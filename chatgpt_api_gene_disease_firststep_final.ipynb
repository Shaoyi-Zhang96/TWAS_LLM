{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b3cdd3-809f-44b2-8c37-789bef4274f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path to your gene-disease file:  C:\\Users\\Shaoyi Zhang\\Desktop\\Jupyter NoteBook\\gene_disease.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory: gene_disease_results\n",
      "\n",
      "Processing pair 1: APOE - alzheimer\n",
      "\n",
      "--------------------------------------------------\n",
      "Processing: APOE association with alzheimer\n",
      "--------------------------------------------------\n",
      "Iteration 1: Model is making tool calls...\n",
      "Fetching information for gene: APOE\n",
      "Searching PubMed for: APOE Alzheimer disease TWAS association\n",
      "Iteration 2: Model is making tool calls...\n",
      "Searching PubMed for: APOE Alzheimer's disease\n",
      "Iteration 3: Model is making tool calls...\n",
      "Searching the web for: APOE Alzheimer's disease TWAS results\n",
      "\n",
      "Final response received.\n",
      "Completed processing APOE association with alzheimer. Results saved to APOE_alzheimer.txt\n",
      "\n",
      "Processing pair 2: TNF - rheumatoid arthritis\n",
      "\n",
      "--------------------------------------------------\n",
      "Processing: TNF association with rheumatoid arthritis\n",
      "--------------------------------------------------\n",
      "Iteration 1: Model is making tool calls...\n",
      "Fetching information for gene: TNF\n",
      "Searching PubMed for: TNF rheumatoid arthritis\n",
      "\n",
      "Final response received.\n",
      "Completed processing TNF association with rheumatoid arthritis. Results saved to TNF_rheumatoid_arthritis.txt\n",
      "\n",
      "Processing pair 3: XYZ123 - diabetes\n",
      "\n",
      "--------------------------------------------------\n",
      "Processing: XYZ123 association with diabetes\n",
      "--------------------------------------------------\n",
      "Iteration 1: Model is making tool calls...\n",
      "Fetching information for gene: XYZ123\n",
      "Iteration 2: Model is making tool calls...\n",
      "Searching the web for: gene XYZ123 diabetes association\n",
      "Iteration 3: Model is making tool calls...\n",
      "Searching PubMed for: gene XYZ123 diabetes association\n",
      "\n",
      "Final response received.\n",
      "Completed processing XYZ123 association with diabetes. Results saved to XYZ123_diabetes.txt\n",
      "\n",
      "All gene-disease pairs have been processed.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, XMLParsedAsHTMLWarning\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import subprocess\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Filter BeautifulSoup warnings about XML being parsed as HTML\n",
    "warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
    "\n",
    "# Check and install required dependencies\n",
    "try:\n",
    "    import lxml\n",
    "except ImportError:\n",
    "    print(\"Installing lxml parser for BeautifulSoup...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lxml\"])\n",
    "    print(\"lxml installed successfully\")\n",
    "\n",
    "# Initialize the client with your API key\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "# Function to search PubMed for scientific articles\n",
    "def search_pubmed(query):\n",
    "    try:\n",
    "        # Search PubMed using E-utilities\n",
    "        base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "        \n",
    "        # First get IDs\n",
    "        search_url = f\"{base_url}esearch.fcgi\"\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'term': query,\n",
    "            'retmode': 'json',\n",
    "            'retmax': 5\n",
    "        }\n",
    "        \n",
    "        response = requests.get(search_url, params=params)\n",
    "        search_data = response.json()\n",
    "        \n",
    "        if 'esearchresult' in search_data and 'idlist' in search_data['esearchresult']:\n",
    "            id_list = search_data['esearchresult']['idlist']\n",
    "            \n",
    "            if not id_list:\n",
    "                return {\"results\": [], \"message\": \"No PubMed articles found.\"}\n",
    "                \n",
    "            # Then get summaries\n",
    "            summary_url = f\"{base_url}esummary.fcgi\"\n",
    "            params = {\n",
    "                'db': 'pubmed',\n",
    "                'id': ','.join(id_list),\n",
    "                'retmode': 'json'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(summary_url, params=params)\n",
    "            summary_data = response.json()\n",
    "            \n",
    "            results = []\n",
    "            if 'result' in summary_data:\n",
    "                for pmid in id_list:\n",
    "                    if pmid in summary_data['result']:\n",
    "                        article = summary_data['result'][pmid]\n",
    "                        title = article.get('title', 'No title available')\n",
    "                        \n",
    "                        # Create result object\n",
    "                        results.append({\n",
    "                            'title': title,\n",
    "                            'link': f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\",\n",
    "                            'pmid': pmid,\n",
    "                            'authors': ', '.join([author.get('name', '') for author in article.get('authors', []) if 'name' in author]),\n",
    "                            'journal': article.get('fulljournalname', 'Journal not specified'),\n",
    "                            'publication_date': article.get('pubdate', 'Date not specified')\n",
    "                        })\n",
    "            \n",
    "            return {\"results\": results, \"message\": f\"Found {len(results)} articles on PubMed.\"}\n",
    "        else:\n",
    "            return {\"results\": [], \"message\": \"No PubMed articles found or error in search.\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"message\": \"Error searching PubMed.\"}\n",
    "\n",
    "# Function to search for gene information in NCBI Gene database\n",
    "def search_gene_info(gene_symbol):\n",
    "    try:\n",
    "        # Search NCBI Gene database using E-utilities\n",
    "        base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "        \n",
    "        # First search for the gene\n",
    "        search_url = f\"{base_url}esearch.fcgi\"\n",
    "        params = {\n",
    "            'db': 'gene',\n",
    "            'term': f\"{gene_symbol}[GENE] AND human[ORGN]\",  # Focus on human genes\n",
    "            'retmode': 'json',\n",
    "            'retmax': 1  # Usually we just want the top match\n",
    "        }\n",
    "        \n",
    "        response = requests.get(search_url, params=params)\n",
    "        search_data = response.json()\n",
    "        \n",
    "        if 'esearchresult' in search_data and 'idlist' in search_data['esearchresult'] and search_data['esearchresult']['idlist']:\n",
    "            gene_id = search_data['esearchresult']['idlist'][0]\n",
    "            \n",
    "            # Then get summary\n",
    "            summary_url = f\"{base_url}esummary.fcgi\"\n",
    "            params = {\n",
    "                'db': 'gene',\n",
    "                'id': gene_id,\n",
    "                'retmode': 'json'\n",
    "            }\n",
    "            \n",
    "            response = requests.get(summary_url, params=params)\n",
    "            summary_data = response.json()\n",
    "            \n",
    "            if 'result' in summary_data and gene_id in summary_data['result']:\n",
    "                gene_data = summary_data['result'][gene_id]\n",
    "                \n",
    "                # Extract relevant information\n",
    "                gene_info = {\n",
    "                    'gene_id': gene_id,\n",
    "                    'symbol': gene_data.get('name', gene_symbol),\n",
    "                    'description': gene_data.get('description', 'No description available'),\n",
    "                    'summary': gene_data.get('summary', 'No summary available'),\n",
    "                    'aliases': gene_data.get('otheraliases', 'No aliases available'),\n",
    "                    'location': gene_data.get('maplocation', 'Location unknown'),\n",
    "                    'ncbi_link': f\"https://www.ncbi.nlm.nih.gov/gene/{gene_id}\"\n",
    "                }\n",
    "                \n",
    "                return {\"info\": gene_info, \"message\": f\"Found gene information for {gene_symbol}\"}\n",
    "            else:\n",
    "                return {\"info\": {}, \"message\": f\"No detailed information found for gene {gene_symbol}\"}\n",
    "        else:\n",
    "            return {\"info\": {}, \"message\": f\"Gene {gene_symbol} not found in NCBI Gene database\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"message\": f\"Error searching gene information for {gene_symbol}\"}\n",
    "\n",
    "# Function to search the web (improved version)\n",
    "def search_web(query):\n",
    "    try:\n",
    "        # Prepare search URL with the query\n",
    "        search_url = f\"https://www.google.com/search?q={query.replace(' ', '+')}\"\n",
    "        \n",
    "        # Request headers to mimic a browser\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        \n",
    "        # Make the request\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract search results\n",
    "        results = []\n",
    "        \n",
    "        # Process Google search results\n",
    "        for g in soup.select('div.g'):\n",
    "            # Extract title\n",
    "            title_elem = g.select_one('h3')\n",
    "            if not title_elem:\n",
    "                continue\n",
    "                \n",
    "            title = title_elem.get_text()\n",
    "            \n",
    "            # Extract URL\n",
    "            link_elem = g.select_one('a')\n",
    "            if not link_elem or 'href' not in link_elem.attrs:\n",
    "                continue\n",
    "                \n",
    "            link = link_elem['href']\n",
    "            if link.startswith('/url?'):\n",
    "                link = re.search(r'/url\\?q=([^&]+)', link).group(1)\n",
    "            elif not link.startswith('http'):\n",
    "                continue\n",
    "                \n",
    "            # Extract snippet\n",
    "            snippet_elem = g.select_one('.VwiC3b, .st')\n",
    "            snippet = snippet_elem.get_text() if snippet_elem else \"No description available\"\n",
    "            \n",
    "            # Check if this is a scholarly/medical source\n",
    "            is_scholarly = any(domain in link.lower() for domain in [\n",
    "                'nih.gov', 'ncbi.nlm', 'pubmed', 'nature.com', 'sciencedirect',\n",
    "                'scholar.google', 'researchgate', 'academic', 'science', 'journal',\n",
    "                'medical', 'health', 'gene', 'genomic', 'genetics', 'omics'\n",
    "            ])\n",
    "            \n",
    "            # Add to results\n",
    "            results.append({\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'snippet': snippet,\n",
    "                'is_scholarly': is_scholarly\n",
    "            })\n",
    "            \n",
    "            # Limit results\n",
    "            if len(results) >= 5:\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"results\": results,\n",
    "            \"message\": f\"Found {len(results)} web results for '{query}'.\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"message\": \"Error during web search.\"}\n",
    "\n",
    "# Function to fetch abstracts for a specific PubMed article\n",
    "def fetch_pubmed_abstract(pmid):\n",
    "    try:\n",
    "        # Use E-utilities to fetch the abstract\n",
    "        base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "        fetch_url = f\"{base_url}efetch.fcgi\"\n",
    "        params = {\n",
    "            'db': 'pubmed',\n",
    "            'id': pmid,\n",
    "            'retmode': 'xml'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(fetch_url, params=params)\n",
    "        \n",
    "        # Try multiple parser approaches to handle different XML formats\n",
    "        try:\n",
    "            # First attempt with lxml-xml\n",
    "            soup = BeautifulSoup(response.text, features=\"lxml-xml\")\n",
    "        except Exception as e:\n",
    "            print(f\"XML parsing with lxml-xml failed: {e}\")\n",
    "            try:\n",
    "                # Second attempt with xml parser\n",
    "                soup = BeautifulSoup(response.text, features=\"xml\")\n",
    "            except Exception as e:\n",
    "                print(f\"XML parsing with xml failed: {e}\")\n",
    "                # Fall back to html parser as last resort\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract the abstract text\n",
    "        abstract_element = soup.find('AbstractText')\n",
    "        if abstract_element:\n",
    "            abstract = abstract_element.get_text()\n",
    "        else:\n",
    "            # Try alternative approach if the first method fails\n",
    "            abstract_sections = soup.find_all('AbstractText')\n",
    "            if abstract_sections:\n",
    "                abstract = \" \".join([section.get_text() for section in abstract_sections])\n",
    "            else:\n",
    "                abstract = \"Abstract not available for this article.\"\n",
    "            \n",
    "        title_element = soup.find('ArticleTitle')\n",
    "        title = title_element.get_text() if title_element else \"Title not available\"\n",
    "        \n",
    "        return {\n",
    "            \"pmid\": pmid,\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract,\n",
    "            \"url\": f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"pmid\": pmid, \"message\": \"Error fetching abstract.\"}\n",
    "\n",
    "# Function to fetch content from a webpage\n",
    "def fetch_webpage(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Remove script and style elements\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "        \n",
    "        # Get text\n",
    "        text = soup.get_text(separator='\\n', strip=True)\n",
    "        \n",
    "        # Truncate if too long (OpenAI has token limits)\n",
    "        max_length = 8000\n",
    "        if len(text) > max_length:\n",
    "            text = text[:max_length] + \"... [Content truncated due to length]\"\n",
    "            \n",
    "        return {\"content\": text, \"url\": url}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"url\": url}\n",
    "\n",
    "# Function to process a gene-disease pair and store results\n",
    "def process_gene_disease_pair(gene, disease):\n",
    "    print(f\"\\n{'-' * 50}\")\n",
    "    print(f\"Processing: {gene} association with {disease}\")\n",
    "    print(f\"{'-' * 50}\")\n",
    "    \n",
    "    # Create a safe filename\n",
    "    filename = f\"{gene.replace(' ', '_')}_{disease.replace(' ', '_')}.txt\"\n",
    "    \n",
    "    # Define available functions\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"search_pubmed\",\n",
    "                \"description\": \"Search PubMed for scientific articles about genes and diseases\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query for PubMed\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"search_gene_info\",\n",
    "                \"description\": \"Search for information about a specific gene in NCBI Gene database\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"gene_symbol\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The gene symbol to search for\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"gene_symbol\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"search_web\",\n",
    "                \"description\": \"Search the web for general information\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The search query\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"fetch_pubmed_abstract\",\n",
    "                \"description\": \"Fetch the abstract for a specific PubMed article by its ID\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"pmid\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The PubMed ID (PMID) of the article\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"pmid\"]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"fetch_webpage\",\n",
    "                \"description\": \"Fetch the content of a webpage\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"url\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The URL to fetch\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"url\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Initialize conversation with a specific query about the gene and disease\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with knowledge about genetics, genomics, and medical research. You can search for gene information, scientific literature, and analyze relationships between genes and diseases, particularly from TWAS (Transcriptome-Wide Association Study) results.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Analyze the association between gene {gene} and {disease} based on TWAS results. Research the function of this gene, its potential role in disease pathways, existing evidence for its involvement in {disease}, and functional mechanisms that might explain this association. Provide a comprehensive analysis including molecular mechanisms, expression patterns, and potential therapeutic implications.\"}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Create output file\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(f\"Analysis of {gene} association with {disease}\\n\")\n",
    "            output_file.write(f\"{'-' * 50}\\n\\n\")\n",
    "            \n",
    "            # Get initial response from the model\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=\"auto\"\n",
    "            )\n",
    "            \n",
    "            response_message = response.choices[0].message\n",
    "            \n",
    "            # Log all messages to the file for complete conversation tracking\n",
    "            def log_message(role, content):\n",
    "                output_file.write(f\"[{role.upper()}]: {content}\\n\\n\")\n",
    "                output_file.write(f\"{'-' * 30}\\n\\n\")\n",
    "            \n",
    "            # Check if the model wants to call a function\n",
    "            iteration = 0\n",
    "            max_iterations = 10  # Limit to prevent infinite loops\n",
    "            \n",
    "            while hasattr(response_message, 'tool_calls') and response_message.tool_calls and iteration < max_iterations:\n",
    "                iteration += 1\n",
    "                print(f\"Iteration {iteration}: Model is making tool calls...\")\n",
    "                \n",
    "                # Add the assistant's message to the history\n",
    "                messages.append(response_message)\n",
    "                log_message(\"assistant\", f\"Making the following tool calls: {[tc.function.name for tc in response_message.tool_calls]}\")\n",
    "                \n",
    "                # Process each tool call\n",
    "                for tool_call in response_message.tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_args = json.loads(tool_call.function.arguments)\n",
    "                    \n",
    "                    # Call the appropriate function\n",
    "                    function_response = None\n",
    "                    if function_name == \"search_pubmed\":\n",
    "                        query = function_args.get(\"query\")\n",
    "                        print(f\"Searching PubMed for: {query}\")\n",
    "                        function_response = search_pubmed(query)\n",
    "                        log_message(\"tool\", f\"search_pubmed query: {query}\\nResults: {json.dumps(function_response, indent=2)}\")\n",
    "                    elif function_name == \"search_gene_info\":\n",
    "                        gene_symbol = function_args.get(\"gene_symbol\")\n",
    "                        print(f\"Fetching information for gene: {gene_symbol}\")\n",
    "                        function_response = search_gene_info(gene_symbol)\n",
    "                        log_message(\"tool\", f\"search_gene_info gene: {gene_symbol}\\nResults: {json.dumps(function_response, indent=2)}\")\n",
    "                    elif function_name == \"search_web\":\n",
    "                        query = function_args.get(\"query\")\n",
    "                        print(f\"Searching the web for: {query}\")\n",
    "                        function_response = search_web(query)\n",
    "                        log_message(\"tool\", f\"search_web query: {query}\\nResults: {json.dumps(function_response, indent=2)}\")\n",
    "                    elif function_name == \"fetch_pubmed_abstract\":\n",
    "                        pmid = function_args.get(\"pmid\")\n",
    "                        print(f\"Fetching abstract for PubMed ID: {pmid}\")\n",
    "                        function_response = fetch_pubmed_abstract(pmid)\n",
    "                        log_message(\"tool\", f\"fetch_pubmed_abstract pmid: {pmid}\\nResults: {json.dumps(function_response, indent=2)}\")\n",
    "                    elif function_name == \"fetch_webpage\":\n",
    "                        url = function_args.get(\"url\")\n",
    "                        print(f\"Fetching webpage: {url}\")\n",
    "                        function_response = fetch_webpage(url)\n",
    "                        # Log URL and truncated content to avoid huge files\n",
    "                        content_preview = function_response.get(\"content\", \"\")[:1000] + \"...\" if \"content\" in function_response else \"\"\n",
    "                        log_message(\"tool\", f\"fetch_webpage url: {url}\\nContent preview: {content_preview}\")\n",
    "                    \n",
    "                    # Add the function result to the messages\n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": json.dumps(function_response)\n",
    "                    })\n",
    "                \n",
    "                # Get the next response after tool use\n",
    "                next_response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=messages,\n",
    "                    tools=tools,\n",
    "                    tool_choice=\"auto\"\n",
    "                )\n",
    "                \n",
    "                response_message = next_response.choices[0].message\n",
    "                \n",
    "                # If no more tool calls, break the loop\n",
    "                if not hasattr(response_message, 'tool_calls') or not response_message.tool_calls:\n",
    "                    ai_response = response_message.content\n",
    "                    print(\"\\nFinal response received.\")\n",
    "                    log_message(\"final_response\", ai_response)\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "                    break\n",
    "            \n",
    "            # Add final summary if we reached max iterations\n",
    "            if iteration >= max_iterations:\n",
    "                print(\"Reached maximum number of iterations. Requesting final summary...\")\n",
    "                final_prompt = {\"role\": \"user\", \"content\": \"Please provide a final comprehensive summary of all the information you've gathered about this gene-disease relationship, including molecular mechanisms, pathways, cell lines, and potential therapeutic implications.\"}\n",
    "                messages.append(final_prompt)\n",
    "                log_message(\"user\", final_prompt[\"content\"])\n",
    "                \n",
    "                final_response = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    messages=messages\n",
    "                )\n",
    "                \n",
    "                final_answer = final_response.choices[0].message.content\n",
    "                log_message(\"final_summary\", final_answer)\n",
    "            \n",
    "            print(f\"Completed processing {gene} association with {disease}. Results saved to {filename}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {gene} for {disease}: {e}\")\n",
    "        # Write error to file\n",
    "        with open(filename, \"a\", encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(f\"ERROR: {str(e)}\\n\")\n",
    "\n",
    "# Main function to read input file and process each pair\n",
    "def process_input_file(input_file_path):\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        output_dir = \"gene_disease_results\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            print(f\"Created output directory: {output_dir}\")\n",
    "        \n",
    "        # Change to output directory\n",
    "        os.chdir(output_dir)\n",
    "        \n",
    "        # Read the input file\n",
    "        with open(input_file_path, 'r') as file:\n",
    "            # Determine if the file is tab-separated or comma-separated\n",
    "            first_line = file.readline().strip()\n",
    "            if '\\t' in first_line:\n",
    "                delimiter = '\\t'\n",
    "            else:\n",
    "                delimiter = ','\n",
    "            \n",
    "            # Return to the beginning of the file\n",
    "            file.seek(0)\n",
    "            \n",
    "            # Create a CSV reader\n",
    "            reader = csv.reader(file, delimiter=delimiter)\n",
    "            \n",
    "            # Process each row\n",
    "            for i, row in enumerate(reader):\n",
    "                if len(row) >= 2:\n",
    "                    gene = row[0].strip()\n",
    "                    disease = row[1].strip()\n",
    "                    \n",
    "                    if gene and disease:  # Ensure neither is empty\n",
    "                        print(f\"\\nProcessing pair {i+1}: {gene} - {disease}\")\n",
    "                        process_gene_disease_pair(gene, disease)\n",
    "                    else:\n",
    "                        print(f\"Skipping row {i+1}: Missing gene or disease\")\n",
    "                else:\n",
    "                    print(f\"Skipping row {i+1}: Insufficient columns\")\n",
    "                \n",
    "        print(\"\\nAll gene-disease pairs have been processed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing input file: {e}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = input(\"Enter the path to your gene-disease file: \")\n",
    "    process_input_file(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f5b98-2511-4f39-8e70-844853c84739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
